#!/usr/bin/env tsx
import { ChatOpenAI } from '@langchain/openai';
import { ToolNode, MessagesAnnotation } from '@langchain/langgraph';
import { StateGraph } from '@langchain/langgraph';
import { HumanMessage } from '@langchain/core/messages';
import { McpClientTool } from '@langchain/langgraph-mcp'; // <-- Ключевой импорт

// === 1. Создаем MCP-клиентский инструмент ===
// Он автоматически запустит наш сервер и загрузит все его инструменты.
const mcpTool = new McpClientTool({
  // Указываем команду для запуска нашего MCP-сервера
  command: ['tsx', './mcp-fs-server-high-level.ts'],
  // Библиотека сама управяет жизненным циклом процесса
});

// === 2. Получаем список всех инструментов, предоставляемых MCP-сервером ===
// `getTools()` возвращает массив стандартных LangChain-инструментов.
const tools = await mcpTool.getTools();
const toolNode = new ToolNode(tools);

// === 3. Настраиваем модель и граф, как обычно ===
const model = new ChatOpenAI({
  model: 'gpt-4o-mini',
  temperature: 0,
}).bindTools(tools);

const shouldContinue = (state: typeof MessagesAnnotation.State) => {
  const messages = state.messages;
  const lastMessage = messages[messages.length - 1];
  if ('tool_calls' in lastMessage && lastMessage.tool_calls?.length) {
    return 'tools';
  }
  return '__end__';
};

const callModel = async (state: typeof MessagesAnnotation.State) => {
  const messages = state.messages;
  const response = await model.invoke(messages);
  return { messages: [response] };
};

const workflow = new StateGraph(MessagesAnnotation)
  .addNode('agent', callModel)
  .addNode('tools', toolNode)
  .addEdge('__start__', 'agent')
  .addConditionalEdges('agent', shouldContinue)
  .addEdge('tools', 'agent');

const app = workflow.compile();

// === 4. Запускаем агента ===
const main = async () => {
  console.log(
    'Доступные инструменты от MCP:',
    tools.map((t) => t.name),
  );

  const inputs = {
    messages: [
      new HumanMessage(
        "Создай папку 'output' и внутри нее файл 'result.txt' с содержимым 'Generated by LangGraph + MCP!'",
      ),
    ],
  };

  for await (const event of await app.stream(inputs)) {
    // Логика вывода событий остается прежней
    for (const [nodeName, nodeState] of Object.entries(event)) {
      if (nodeName === 'agent') {
        const aiMsg = nodeState.messages[0];
        if ('tool_calls' in aiMsg && aiMsg.tool_calls?.length) {
          console.log(
            'Агент вызывает инструменты:',
            aiMsg.tool_calls.map((tc) => tc.name),
          );
        }
      }
    }
  }

  // Проверка результата
  console.log(
    "\nСодержимое файла 'output/result.txt':",
    fs.readFileSync('output/result.txt', 'utf8'),
  );

  // Важно: закрываем клиент, чтобы завершить дочерний процесс MCP-сервера
  await mcpTool.close();
};

main().catch(console.error);
